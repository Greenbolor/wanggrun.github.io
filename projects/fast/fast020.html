<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<!-- Meta tags for search engines to crawl -->
<meta name="robots" content="index,follow">
<meta name="keywords" content="Guangrun Wang; 王广润; Machine Learning; Computer Vision; Sun Yat-sen University; SYSU; HCP">
<link rel="author" href="https://wanggrun.github.io/">

    <title>Guangrun Wang (王广润)'s Homepage</title>
    <style>

@media screen and (max-device-width: 480px){
  body{
    -webkit-text-size-adjust: none;
  }
}
p { font-size : 16px; }
h1 { font-size : 34px; margin : 0; padding : 0; }
h2 { font-size : 20px; margin : 0; padding : 0; }
h3 { font-size : 18px; margin : 8; padding : 0; }
body { padding : 0; font-family : Arial; font-size : 16px; background-color : #fff; }
.title { width : 650px; margin : 20px auto; }
.container { width : 750px; margin : 20px auto; border-radius: 10px;  background-color : #fff; padding : 20px;  clear:both;}
#bio {
    padding-top : 40px;
}
#me { border : 0 solid black; margin-bottom : 50px; border-radius : 10px; }
#sidebar { margin-left : 25px; border : 0 solid black; float : right; margin-bottom : 0;}
a { text-decoration : none; }
a:hover { text-decoration : underline; }
a, a:visited { color : #0050e7; }
.publogo { width: 100 px; margin-right : 20px; float : left; border : 0;}
.publication { clear : left; padding-bottom : 0px; }
.publication p { height : 100px; padding-top : 5px;}
.publication strong a { color : #0000A0; }
.publication .links { position : relative; top : 15px }
.publication .links a { margin-right : 20px; }
.codelogo { margin-right : 10px; float : left; border : 0;}
.code { clear : left; padding-bottom : 10px; vertical-align :middle;} 
.code .download a { display : block; margin : 0 15px; float : left;}
.code strong a { color : #000; }
.external a { margin : 0 10px; }
.external a.first { margin : 0 10px 0 0; }
    </style>
    <script async="" src="../homepage_files/analytics.js"></script>
</head>

<body>
    <div class="title">
            <h1>
                <span itemprop="name"><font size="5">阅读谷歌工作：优化器SAM的论文和代码</font> </span>
            </h1>
    </div>
    <div class="container">
      <p>

      根据论文《When Vision Transformers Outperform ResNets》，可以知道，优化器SAM对过拟合抑制，对泛化性的提交很有帮助。很让人有所启发。对我以往的工作有很多rethinking。所以阅读了SAM的论文和代码。<br><br>

      论文：https://openreview.net/pdf?id=6Tm1mposlrM。发表于iclr 2021。短短时间引用26次
      代码：https://github.com/google-research/sam/blob/dae9904c4cf3a57a304f7b04cecffe371679c702/sam_jax/training_utils/flax_training.py#L466<br><br>

      论文里的核心部分是：<br><br>

      先前向->反向，求一个\epsilon。计算公式为：<br><br>

      <div align="center"><img src="./images/fast20_1.png" vspace="0 px" width="700 px" id="fast" itemprop="photo"></div>
      <br><br>

      假装以w+\epsilon为参数，再前向->反向，求一个\delta w，计算公式如下：<br><br>

      <div align="center"><img src="./images/fast20_2.png" vspace="0 px" width="700 px" id="fast" itemprop="photo"></div>
      <br><br>


      回到w点，\delta w更新w即可。<br><br>

      算法框架为：<br><br>

      <div align="center"><img src="./images/fast20_3.png" vspace="0 px" width="700 px" id="fast" itemprop="photo"></div>
      <br><br>


      主要实现的代码如下：<br><br>
      第一次前向+反向：<br>

      (_, (inner_state, _)), grad = jax.value_and_grad(
      lambda m: forward_and_loss(m, true_gradient=True), has_aux=True)(model)<br>


      noised_model = jax.tree_multimap(lambda a, b: a + rho * b,
      model, grad)<br>

      第二次前向+反向：<br><br>

      (_, (_, logits)), grad = jax.value_and_grad(
      forward_and_loss, has_aux=True)(noised_model)<br>

      #clip一下梯度且更新<br>

      grad = clip_by_global_norm(grad)
      new_optimizer = optimizer.apply_gradient(grad, learning_rate=lr)<br>


      # Compute some norms to log on tensorboard.<br>
      gradient_norm = jnp.sqrt(sum(
      [jnp.sum(jnp.square(e)) for e in jax.tree_util.tree_leaves(grad)]))<br>
      param_norm = jnp.sqrt(sum(
      [jnp.sum(jnp.square(e)) for e in jax.tree_util.tree_leaves(
      new_optimizer.target)]))


       <br><br>
       <br><br>
       -----------------------------------
       <br><br>
       大家好，我来自fast lab。我开始不定时公开写作。这些写作主要通过两个渠道公布：一是FAST LAB官方网站；一是印象识堂（微信可访问）。欢迎大家订阅。谢谢！
       <br><br>
       FAST Lab的官方网址为：<a href="https://wanggrun.github.io/projects/fast">https://wanggrun.github.io/projects/fast</a>
       <br><br>
       除此外，还可以关注我的小伙伴王广润：<a href="https://wanggrun.github.io/">https://wanggrun.github.io/</a> 
       <br><br>
       王广聪： <a href="https://wanggcong.github.io/">https://wanggcong.github.io/</a> 
       <br><br>
       石阳：<a href="https://www.linkedin.com/in/%E9%98%B3-%E7%9F%B3-381b521a4/">https://www.linkedin.com/in/%E9%98%B3-%E7%9F%B3-381b521a4/</a>
       <br><br>
       有时候这些网站打不开，请耐心多点几次。
       <br><br>
       多谢大家关注。
       <p><p>
       </p>
       <p>
       <a href="https://wanggrun.github.io/projects/fast">返回博客目录Return to all Blogs</a>
       <br>
       <a href="https://wanggrun.github.io/">返回主页Return to homepage</a>
       </p>
    </div>
 
</body></html>


